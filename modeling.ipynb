{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from models.unet import *\n",
    "from models.simple_model import *\n",
    "from models.tri_unet import *\n",
    "from models.divergent_nets import *\n",
    "from utils.data_utils.acdc_datamodule import *\n",
    "from utils.data_utils.data_utils import *\n",
    "from utils.model_utils.dice_score import *\n",
    "from utils.model_utils.resnet_loss import ResnetLoss \n",
    "\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmanter(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, criterion) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        return model_output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred_y = self(x)\n",
    "\n",
    "        # train dice\n",
    "        y_pred = torch.argmax(pred_y[2], axis=1)\n",
    "        y_pred_onehot = F.one_hot(y_pred, 4).permute(0, 3, 1, 2)\n",
    "        dice = self.compute_dice(y_pred_onehot, y)\n",
    "        dice_LV = dice[3]\n",
    "        dice_RV = dice[1]\n",
    "        dice_MYO = dice[2]\n",
    "        self.log('dice/all_train_dice', dice[1:].mean(), on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        self.log('dice/train_LV_dice', dice_LV, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        self.log('dice/train_RV_dice', dice_RV, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        self.log('dice/train_MYO_dice', dice_MYO, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        # save grad\n",
    "        for name, params in self.named_parameters():\n",
    "            if params.grad is not None:\n",
    "                self.log(f'abs_{name}',params.grad.abs().mean(), on_epoch=True)\n",
    "        return loss #TODO\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constans and Hyperparams\n",
    "NUM_CLASSES = 4\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "# Big model takes lots of space in memory -> small batch size fits in\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VAL = 8\n",
    "BATCH_SIZE_TEST  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = DualTransform(20,0.2,0.2)\n",
    "datamodule = ACDCDataModule(\"database\", BATCH_SIZE_TRAIN,BATCH_SIZE_VAL,BATCH_SIZE_TEST,(256,256,1), convert_to_single=False, transform=transform)\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diceloss kiegyensúlyozatlan osztályokra\n",
    "# CrossEntropy is jó lehet, de Dice is jó \n",
    "# Jacquard index - IoU\n",
    "# ignore index kipróbálása -> metrikánál mindenképp érdemes\n",
    "#  1 ignorált klassznak lehet nincs hatása\n",
    "#  ignorált osztály -> lehet crossentropy is azonos hatékonyságú\n",
    "#  osztályonkénti dice coeff\n",
    "# split betegenként, fixáljuk a validációs halmazt\n",
    "#  KFold ha nem fixálunk -> ez is lehet ensemble\n",
    "# pixelszintű tévesztési mátrix, pixel accuracy \n",
    "#  legyenek példapredikciók\n",
    "#  kvalitatív kiértékelés\n",
    "\n",
    "criterion = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "loss = ResnetLoss(criterion)\n",
    "loss = criterion\n",
    "# loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Callback\n",
    "\n",
    "class_labels = {\n",
    "  0: \"background\",\n",
    "  1: \"RV\",\n",
    "  2: \"myocardium\",\n",
    "  3: \"LV\"\n",
    "}\n",
    "\n",
    "class Visualizer(Callback):\n",
    "    def on_validation_epoch_start(self, trainer, model):\n",
    "        x = trainer.datamodule.acdc_val[0][0]\n",
    "        y = trainer.datamodule.acdc_val[0][1]\n",
    "        pred = model(x.unsqueeze(0).to('cuda'))\n",
    "        gt_mask = np.array(y.squeeze())\n",
    "        pred_mask = np.array(torch.argmax(pred.squeeze().cpu(), dim=0))\n",
    "        error = (gt_mask == pred_mask).astype(np.uint8)\n",
    "        trainer.logger.experiment.log(\n",
    "            {\"visualizing\":[\n",
    "                    wandb.Image(x, caption=\"GT\", masks={\n",
    "                        \"segmentation\": {\n",
    "                            \"mask_data\": gt_mask,\n",
    "                            \"class_labels\": class_labels\n",
    "                        },\n",
    "                    }),\n",
    "                    wandb.Image(x, caption=\"pred\", masks={\n",
    "                        \"segmentation\": {\n",
    "                            \"mask_data\": pred_mask,\n",
    "                            \"class_labels\": class_labels\n",
    "                        },\n",
    "                    }),\n",
    "                    wandb.Image(error, caption=\"error\"),\n",
    "                ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',  patience=5 ,mode=\"min\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "\n",
    "def fcn_facotory():\n",
    "    model = fcn_resnet50()\n",
    "    model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\boton/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 70.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20231207_232144-ets0phm4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ets0phm4' target=\"_blank\">unet_model</a></strong> to <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ets0phm4' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ets0phm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model     │ Unet     │ 24.4 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion │ DiceLoss │      0 │\n",
       "└───┴───────────┴──────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model     │ Unet     │ 24.4 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion │ DiceLoss │      0 │\n",
       "└───┴───────────┴──────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 24.4 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 24.4 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 97                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 24.4 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 24.4 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 97                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940087c5bebf42e495018a694472fb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_c\n",
       "onnector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_c\n",
       "onnector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_c\n",
       "onnector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_c\n",
       "onnector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.323 >= min_delta = 0.0. New best score: 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.124 >= min_delta = 0.0. New best score: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.038 >= min_delta = 0.0. New best score: 0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.106. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafaa5ad9aa44a1590b81977e2a69c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.169 MB of 1.169 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▃▂▂▂▂▁▁▂▁▁▁▁▂▁▁▁▂▁▂▁▁▁▂▁▁▂▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>17</td></tr><tr><td>train_loss_epoch</td><td>0.07737</td></tr><tr><td>train_loss_step</td><td>0.06544</td></tr><tr><td>trainer/global_step</td><td>3401</td></tr><tr><td>val_loss</td><td>0.11503</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_model</strong> at: <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ets0phm4' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ets0phm4</a><br/>Synced 5 W&B file(s), 77 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231207_232144-ets0phm4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c87114513f4339a4f8a39e445c7d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01128888888957186, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20231207_235000-tqn91wov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/tqn91wov' target=\"_blank\">fcn_model</a></strong> to <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/tqn91wov' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/tqn91wov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model     │ FCN      │ 32.9 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion │ DiceLoss │      0 │\n",
       "└───┴───────────┴──────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model     │ FCN      │ 32.9 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion │ DiceLoss │      0 │\n",
       "└───┴───────────┴──────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 32.9 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 32.9 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 131                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 32.9 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 32.9 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 131                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34de26f1c6cb4c6e8c1c1b866e236698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Botond\\EGYETEM\\9\\deeplearning\\medical_image_segmentation\\modeling.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m segmenter \u001b[39m=\u001b[39m SemanticSegmanter(model\u001b[39m=\u001b[39mmodel, learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m, criterion\u001b[39m=\u001b[39mloss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, logger\u001b[39m=\u001b[39mwandb_logger, callbacks\u001b[39m=\u001b[39m[RichProgressBar(), Visualizer(), early_stopping])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(segmenter, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[1;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    534\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    567\u001b[0m     ckpt_path,\n\u001b[0;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    570\u001b[0m )\n\u001b[1;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1021\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1020\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1021\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1023\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1050\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1047\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1049\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1050\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1052\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1054\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:102\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_start()\n\u001b[0;32m    103\u001b[0m data_fetcher \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\n\u001b[0;32m    104\u001b[0m \u001b[39massert\u001b[39;00m data_fetcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:235\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_evaluation_start()\n\u001b[1;32m--> 235\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_evaluation_epoch_start()\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:317\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_start\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m trainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mon_epoch_start()\n\u001b[0;32m    316\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_epoch_start\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_epoch_start\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 317\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(trainer, hook_name, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    318\u001b[0m call\u001b[39m.\u001b[39m_call_lightning_module_hook(trainer, hook_name, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\boton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:195\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[0;32m    194\u001b[0m         \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 195\u001b[0m             fn(trainer, trainer\u001b[39m.\u001b[39mlightning_module, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[0;32m    198\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "\u001b[1;32md:\\Botond\\EGYETEM\\9\\deeplearning\\medical_image_segmentation\\modeling.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m gt_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y\u001b[39m.\u001b[39msqueeze())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pred_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(torch\u001b[39m.\u001b[39margmax(pred\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39mcpu(), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m error \u001b[39m=\u001b[39m (gt_mask \u001b[39m==\u001b[39m pred_mask)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m trainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39mlog(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mvisualizing\u001b[39m\u001b[39m\"\u001b[39m:[\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             wandb\u001b[39m.\u001b[39mImage(x, caption\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGT\u001b[39m\u001b[39m\"\u001b[39m, masks\u001b[39m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Botond/EGYETEM/9/deeplearning/medical_image_segmentation/modeling.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     })\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "# Unet\n",
    "unet_model = smp.Unet('resnet34', classes=NUM_CLASSES, in_channels=1)\n",
    "\n",
    "# Fcn\n",
    "fcn_model = fcn_facotory()\n",
    "\n",
    "# TriUnet - 3 unet\n",
    "feature_models = torch.nn.ModuleList([smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=1) for _ in range(2)])\n",
    "triunet_3unet_model = TriUnet(feature_models, smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "# # TriUnet - 3 fcn\n",
    "# feature_models = torch.nn.ModuleList([fcn_facotory() for _ in range(2)])\n",
    "# triunet_3fcn_model = TriUnet(feature_models, fcn_facotory())\n",
    "\n",
    "# TriUnet - 2 fcn + unet\n",
    "feature_models = torch.nn.ModuleList([fcn_facotory() for _ in range(2)])\n",
    "triunet_2fcn_1unet_model = TriUnet(feature_models, smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "models = [\n",
    "    (\"unet_model\", unet_model),\n",
    "    (\"fcn_model\", fcn_model),\n",
    "    (\"triunet_3unet_model\", triunet_3unet_model),\n",
    "    # (\"triunet_3fcn_model\", triunet_3fcn_model),\n",
    "    (\"triunet_2fcn_1unet_model\", triunet_2fcn_1unet_model)\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    wandb_logger = pl.loggers.WandbLogger(project=\"Medical Image Segmentation\", name=name)\n",
    "    wandb_logger.watch(model)\n",
    "    segmenter = SemanticSegmanter(model=model, learning_rate=1e-4, criterion=loss)\n",
    "    trainer = pl.Trainer(max_epochs=30, logger=wandb_logger, callbacks=[RichProgressBar(), Visualizer(), early_stopping])\n",
    "    trainer.fit(segmenter, datamodule=datamodule)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "model1 = smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=1).cuda()\n",
    "model2 = UNet(n_channels=1, n_classes=4).cuda()\n",
    "model3 = fcn_resnet50()\n",
    "model3.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model3.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "model3 = model3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.7235326766967773 seconds\n",
      "Time taken: 14.67308259010315 seconds\n",
      "Time taken: 6.882024526596069 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "criterion = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "for ix, m in enumerate([model1, model2, model3]):\n",
    "    m.train()\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    for x,y in datamodule.train_dataloader():\n",
    "        out = m(x.to(\"cuda\"))\n",
    "        if ix == 2:\n",
    "            loss = ResnetLoss(criterion)\n",
    "            loss(out, y.to(\"cuda\").long()).backward()\n",
    "        else:\n",
    "            criterion(out, y.to(\"cuda\").long()).backward()\n",
    "        i+=1\n",
    "        if i>3:\n",
    "            break\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_dice(self, pred_y, y):\n",
    "        \"\"\"\n",
    "        Computes the Dice coefficient for each class in the ACDC dataset.\n",
    "        Assumes binary masks with shape (num_masks, num_classes, height, width).\n",
    "        \"\"\"\n",
    "        epsilon = 1e-6\n",
    "        num_masks = pred_y.shape[0]\n",
    "        num_classes = pred_y.shape[1]\n",
    "        dice_scores = torch.zeros((num_classes,), device=self.device)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            intersection = torch.sum(pred_y[:, c] * y[:, c])\n",
    "            sum_masks = torch.sum(pred_y[:, c]) + torch.sum(y[:, c])\n",
    "            dice_scores[c] = (2. * intersection + epsilon) / (sum_masks + epsilon)\n",
    "        print(dice_scores)\n",
    "        return dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(Callback):\n",
    "    def on_test_epoch_start(self, trainer, model):\n",
    "        x = trainer.datamodule.acdc_val[0][0]\n",
    "        y = trainer.datamodule.acdc_val[0][1]\n",
    "        pred = model(x.unsqueeze(0).to('cuda'))\n",
    "        gt_mask = np.array(y.squeeze())\n",
    "        pred_mask = np.array(torch.argmax(pred.squeeze().cpu(), dim=0))\n",
    "        y_pred_onehot = F.one_hot(pred_mask, 4).permute(0, 3, 1, 2)\n",
    "        dice = compute_dice(y_pred_onehot, gt_mask)\n",
    "        dice_LV = dice[3]\n",
    "        dice_RV = dice[1]\n",
    "        dice_MYO = dice[2]\n",
    "        self.log('dice/all_train_dice', dice[1:].mean(), on_epoch=True)\n",
    "        self.log('dice/train_LV_dice', dice_LV, on_epoch=True)\n",
    "        self.log('dice/train_RV_dice', dice_RV, on_epoch=True)\n",
    "        self.log('dice/train_MYO_dice', dice_MYO, on_epoch=True)\n",
    "        # save grad\n",
    "        for name, params in self.named_parameters():\n",
    "            if params.grad is not None:\n",
    "                self.log(f'abs_{name}',params.grad.abs().mean(), on_epoch=True)\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
