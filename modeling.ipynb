{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from models.unet import *\n",
    "from models.simple_model import *\n",
    "from models.multi_unet import *\n",
    "from models.divergent_nets import *\n",
    "from utils.data_utils.acdc_datamodule import *\n",
    "from utils.data_utils.data_utils import *\n",
    "from utils.model_utils.dice_score import *\n",
    "from utils.model_utils.resnet_loss import ResnetLoss \n",
    "\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenyakbence19\u001b[0m (\u001b[33mbence\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmanter(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, criterion) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.lr = learning_rate\n",
    "        self.val_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=4)\n",
    "        self.test_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=4)\n",
    "        self.val_dice = torchmetrics.Dice( num_classes=4, ignore_index=0)\n",
    "        self.test_dice = torchmetrics.Dice( num_classes=4, ignore_index=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        return model_output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        \n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.val_acc(masks_pred, ground_truths)\n",
    "        self.val_dice(masks_pred, ground_truths)\n",
    "        \n",
    "        self.log('val_dice', self.val_dice, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\",self.val_acc, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        self.test_dice(masks_pred, ground_truths)\n",
    "        self.log('test_dice', self.test_dice, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"test_acc\",self.test_acc, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constans and Hyperparams\n",
    "NUM_CLASSES = 4\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "# Big model takes lots of space in memory -> small batch size fits in\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VAL = 8\n",
    "BATCH_SIZE_TEST  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = DualTransform(20,0.2,0.2)\n",
    "datamodule = ACDCDataModule(\"database\", BATCH_SIZE_TRAIN,BATCH_SIZE_VAL,BATCH_SIZE_TEST,(256,256,1), convert_to_single=False, transform=transform)\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diceloss kiegyensúlyozatlan osztályokra\n",
    "# CrossEntropy is jó lehet, de Dice is jó \n",
    "# Jacquard index - IoU\n",
    "# ignore index kipróbálása -> metrikánál mindenképp érdemes\n",
    "#  1 ignorált klassznak lehet nincs hatása\n",
    "#  ignorált osztály -> lehet crossentropy is azonos hatékonyságú\n",
    "#  osztályonkénti dice coeff\n",
    "# split betegenként, fixáljuk a validációs halmazt\n",
    "#  KFold ha nem fixálunk -> ez is lehet ensemble\n",
    "# pixelszintű tévesztési mátrix, pixel accuracy \n",
    "#  legyenek példapredikciók\n",
    "#  kvalitatív kiértékelés\n",
    "\n",
    "criterion = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "# loss = ResnetLoss(criterion)\n",
    "loss = criterion\n",
    "# loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Callback\n",
    "\n",
    "class_labels = {\n",
    "  0: \"background\",\n",
    "  1: \"RV\",\n",
    "  2: \"myocardium\",\n",
    "  3: \"LV\"\n",
    "}\n",
    "\n",
    "class Visualizer(Callback):\n",
    "    def on_validation_epoch_start(self, trainer, model):\n",
    "        x = trainer.datamodule.acdc_val[0][0]\n",
    "        y = trainer.datamodule.acdc_val[0][1]\n",
    "        pred = model(x.unsqueeze(0).to('cuda'))\n",
    "        gt_mask = np.array(y.squeeze())\n",
    "        pred_mask = np.array(torch.argmax(pred.squeeze().cpu(), dim=0))\n",
    "        error = (gt_mask == pred_mask).astype(np.uint8)\n",
    "        trainer.logger.experiment.log(\n",
    "            {\"visualizing\":[\n",
    "                    wandb.Image(x, caption=\"GT\", masks={\n",
    "                        \"segmentation\": {\n",
    "                            \"mask_data\": gt_mask,\n",
    "                            \"class_labels\": class_labels\n",
    "                        },\n",
    "                    }),\n",
    "                    wandb.Image(x, caption=\"pred\", masks={\n",
    "                        \"segmentation\": {\n",
    "                            \"mask_data\": pred_mask,\n",
    "                            \"class_labels\": class_labels\n",
    "                        },\n",
    "                    }),\n",
    "                    wandb.Image(error, caption=\"error\"),\n",
    "                ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        return self.model(x)[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "\n",
    "def fcn_factory(in_channel = 1):\n",
    "    model = fcn_resnet50()\n",
    "    model.backbone.conv1 = nn.Conv2d(in_channel, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "    return ResnetWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231210_090219-w80t5nrl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/w80t5nrl' target=\"_blank\">triunet_2fcn_1unet_model</a></strong> to <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/w80t5nrl' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/w80t5nrl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model     │ MultiUnet          │ 90.3 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion │ DiceLoss           │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ val_acc   │ MulticlassAccuracy │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ test_acc  │ MulticlassAccuracy │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ val_dice  │ Dice               │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ test_dice │ Dice               │      0 │\n",
       "└───┴───────────┴────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model     │ MultiUnet          │ 90.3 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion │ DiceLoss           │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ val_acc   │ MulticlassAccuracy │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ test_acc  │ MulticlassAccuracy │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ val_dice  │ Dice               │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ test_dice │ Dice               │      0 │\n",
       "└───┴───────────┴────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 90.3 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 90.3 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 361                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 90.3 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 90.3 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 361                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.10/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: \n",
       "PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider\n",
       "increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: \n",
       "PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider\n",
       "increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.525\n",
      "Metric val_loss improved by 0.223 >= min_delta = 0.0. New best score: 0.302\n",
      "Metric val_loss improved by 0.040 >= min_delta = 0.0. New best score: 0.262\n",
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.254\n",
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.245\n",
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.232\n",
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.222\n",
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.222. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of\n",
       "metric MulticlassAccuracy was called before the ``update`` method which may lead to errors, as metric states have \n",
       "not yet been updated.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of\n",
       "metric MulticlassAccuracy was called before the ``update`` method which may lead to errors, as metric states have \n",
       "not yet been updated.\n",
       "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_dice         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7454051971435547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.21935603022575378    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_dice        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7454051971435547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.21935603022575378   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_dice</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▄▃▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▃▁▁▂▁▁▁▂▁▁▃▁▃▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▇▇███████████</td></tr><tr><td>val_dice</td><td>▁▇▅▇▇▇████▇███</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>test_acc</td><td>0.0</td></tr><tr><td>test_dice</td><td>0.74541</td></tr><tr><td>test_loss</td><td>0.21936</td></tr><tr><td>train_loss_epoch</td><td>0.15796</td></tr><tr><td>train_loss_step</td><td>0.13842</td></tr><tr><td>trainer/global_step</td><td>2646</td></tr><tr><td>val_acc</td><td>0.98392</td></tr><tr><td>val_dice</td><td>0.7353</td></tr><tr><td>val_loss</td><td>0.22343</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">triunet_2fcn_1unet_model</strong> at: <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/w80t5nrl' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/w80t5nrl</a><br/>Synced 6 W&B file(s), 61 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231210_090219-w80t5nrl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unet\n",
    "unet_model = smp.Unet('resnet34', classes=NUM_CLASSES, in_channels=1)\n",
    "unet_model_pretrained = smp.Unet('resnet34', classes=NUM_CLASSES, in_channels=1, encoder_weights='imagenet')\n",
    "unet_model_resnet50_pretrained = smp.Unet('resnet50', classes=NUM_CLASSES, in_channels=1, encoder_weights='imagenet')\n",
    "\n",
    "\n",
    "\n",
    "# Unet++\n",
    "# unet_plusplus_model = smp.UnetPlusPlus('resnet34', classes=NUM_CLASSES, in_channels=1, encoder_weights='imagenet')\n",
    "# unet_plusplus_model_resnet50 = smp.UnetPlusPlus('resnet50', classes=NUM_CLASSES, in_channels=1, encoder_weights='imagenet')\n",
    "\n",
    "# Fcn\n",
    "fcn_model = fcn_factory()\n",
    "\n",
    "# TriUnet - 3 unet\n",
    "feature_models = torch.nn.ModuleList([smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=1) for _ in range(2)])\n",
    "triunet_3unet_model = MultiUnet(feature_models, smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "feature_models = torch.nn.ModuleList([smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=1) for _ in range(3)])\n",
    "quadrunet_4unet_model = MultiUnet(feature_models, smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "# # TriUnet - 3 fcn\n",
    "feature_models = torch.nn.ModuleList([fcn_factory(1) for _ in range(2)])\n",
    "triunet_3fcn_model = MultiUnet(feature_models, fcn_factory(len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "# TriUnet - 2 fcn + unet\n",
    "feature_models = torch.nn.ModuleList([fcn_factory(1) for _ in range(2)])\n",
    "triunet_2fcn_1unet_model = MultiUnet(feature_models, smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=len(feature_models)*NUM_CLASSES))\n",
    "\n",
    "models = [\n",
    "    (\"unet_model\", unet_model),\n",
    "    (\"unet_model_pretrained\", unet_model_pretrained),\n",
    "    (\"fcn_model\", fcn_model),\n",
    "    (\"triunet_3unet_model\", triunet_3unet_model),\n",
    "    (\"quadrunet_4unet_model\", quadrunet_4unet_model),\n",
    "    (\"triunet_3fcn_model\", triunet_3fcn_model),\n",
    "    (\"triunet_2fcn_1unet_model\", triunet_2fcn_1unet_model)\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',  patience=5 ,mode=\"min\", verbose=True)\n",
    "    wandb_logger = pl.loggers.WandbLogger(entity='drigba', project=\"Medical Image Segmentation\", name=name)\n",
    "    wandb_logger.watch(model)\n",
    "    segmenter = SemanticSegmanter(model=model, learning_rate=1e-4, criterion=loss)\n",
    "    trainer = pl.Trainer(max_epochs=MAX_EPOCHS, logger=wandb_logger, callbacks=[RichProgressBar(), Visualizer(), early_stopping])\n",
    "    trainer.fit(segmenter, datamodule=datamodule)\n",
    "    trainer.test(segmenter, datamodule=datamodule)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "# ha nem működik használjuk a torchmetrics Dice-ot reduce = None-al, az visszaadja osztályonként a diceCoeff-et ami (1 - diceCoeff) = loss\n",
    "def compute_dice(self, pred_y, y):\n",
    "        \"\"\"\n",
    "        Computes the Dice coefficient for each class in the ACDC dataset.\n",
    "        Assumes binary masks with shape (num_masks, num_classes, height, width).\n",
    "        \"\"\"\n",
    "        epsilon = 1e-6\n",
    "        num_masks = pred_y.shape[0]\n",
    "        num_classes = pred_y.shape[1]\n",
    "        dice_scores = torch.zeros((num_classes,), device=self.device)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            intersection = torch.sum(pred_y[:, c] * y[:, c])\n",
    "            sum_masks = torch.sum(pred_y[:, c]) + torch.sum(y[:, c])\n",
    "            dice_scores[c] = (2. * intersection + epsilon) / (sum_masks + epsilon)\n",
    "        print(dice_scores)\n",
    "        return dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(Callback):\n",
    "    def on_test_epoch_start(self, trainer, model):\n",
    "        x = trainer.datamodule.acdc_val[0][0]\n",
    "        y = trainer.datamodule.acdc_val[0][1]\n",
    "        pred = model(x.unsqueeze(0).to('cuda'))\n",
    "        gt_mask = np.array(y.squeeze())\n",
    "        pred_mask = np.array(torch.argmax(pred.squeeze().cpu(), dim=0))\n",
    "        y_pred_onehot = F.one_hot(pred_mask, 4).permute(0, 3, 1, 2)\n",
    "        dice = compute_dice(y_pred_onehot, gt_mask)\n",
    "        dice_LV = dice[3]\n",
    "        dice_RV = dice[1]\n",
    "        dice_MYO = dice[2]\n",
    "        self.log('dice/all_train_dice', dice[1:].mean(), on_epoch=True)\n",
    "        self.log('dice/train_LV_dice', dice_LV, on_epoch=True)\n",
    "        self.log('dice/train_RV_dice', dice_RV, on_epoch=True)\n",
    "        self.log('dice/train_MYO_dice', dice_MYO, on_epoch=True)\n",
    "        # save grad\n",
    "        for name, params in self.named_parameters():\n",
    "            if params.grad is not None:\n",
    "                self.log(f'abs_{name}',params.grad.abs().mean(), on_epoch=True)\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
