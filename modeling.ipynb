{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import wandb\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from models.unet import *\n",
    "from utils.data_utils.acdc_datamodule import *\n",
    "from utils.data_utils.data_utils import *\n",
    "from utils.model_utils.dice_score import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanfizsombor1999\u001b[0m (\u001b[33mdrigba\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\banfi\\OneDrive\\Asztali g√©p\\Egyetem\\DeepLearning\\big_project\\wandb\\run-20231109_161035-ypbh41s7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ypbh41s7' target=\"_blank\">stellar-voice-15</a></strong> to <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ypbh41s7' target=\"_blank\">https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ypbh41s7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/drigba/Medical%20Image%20Segmentation/runs/ypbh41s7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1a6ebd5b0d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"Medical Image Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmanter(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, criterion) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.test_losses = []\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        loss.requires_grad = True\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.train_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = 1-self.criterion(masks_pred, ground_truths)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        self.val_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.test_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constans and Hyperparams\n",
    "NUM_CLASSES = 4\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "# Big model takes lots of space in memory -> small batch size fits in\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VAL = 4\n",
    "BATCH_SIZE_TEST  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ACDCDataModule(\"database\", BATCH_SIZE_TRAIN,BATCH_SIZE_VAL,BATCH_SIZE_TEST,(256,256,1), convert_to_single=False)\n",
    "datamodule.setup(\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to add new preprocessing arg, to include pretrained model preprocessing\n",
    "# preprocess_input = smp.encoders.get_preprocessing_fn('resnet18', pretrained='imagenet')\n",
    "\n",
    "unet = smp.Unet('resnet18', encoder_weights='imagenet', classes=NUM_CLASSES, activation='softmax', in_channels=1)\n",
    "criterion = torchmetrics.classification.Dice(num_classes=NUM_CLASSES, threshold=0.5)\n",
    "segmenter = SemanticSegmanter(model = unet, learning_rate=1e-3 ,criterion=criterion)\n",
    "\n",
    "# tsmp.metrics.functional.IoU or torch metric?\n",
    "# do we need this?\n",
    "# metric = smp.metrics.functional.IoU(threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\banfi\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\lightning\\pytorch\\loggers\\wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "# Configure callbacks and logger\n",
    "wandb_logger = pl.loggers.WandbLogger()\n",
    "wandb_logger.watch(unet)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  patience=5, mode=\"min\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | model     | Unet | 3.1 M \n",
      "1 | criterion | Dice | 0     \n",
      "-----------------------------------\n",
      "3.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 M     Total params\n",
      "12.351    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc2355f371f4f9893ef1e3cc5bdf217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\banfi\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\banfi\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n",
      "c:\\Users\\banfi\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n",
      "c:\\Users\\banfi\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897d7c00b2ae4483a447ebabb770b6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c971d08e1b48dca3a015c34e28cb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de19fa295d8f40c78cf6c048b6debe62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f53aaac4d54b07be1e2cfdb29b4544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf172fb5e234ab38bb66201d5b109dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeda7a03b7344ff4ac61243d89638ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53667a3597f941afb8a24eea582d224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e551d01b64705a14ed7ce16e1dd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f03e714a8b4d2b8f265a8fe48338bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.541. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=100,  logger=wandb_logger, callbacks=[early_stopping])\n",
    "trainer.fit(segmenter, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
