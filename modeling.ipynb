{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import wandb\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from models.unet import *\n",
    "from models.simple_model import *\n",
    "from utils.data_utils.acdc_datamodule import *\n",
    "from utils.data_utils.data_utils import *\n",
    "from utils.model_utils.dice_score import *\n",
    "from utils.model_utils.resnet_loss import ResnetLoss \n",
    "\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmanter(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, criterion) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_output = self.model(x)\n",
    "        return model_output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        # ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, ground_truths = batch\n",
    "        masks_pred = self.model(images)\n",
    "        ground_truths = ground_truths.long()\n",
    "        loss = self.criterion(masks_pred, ground_truths)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constans and Hyperparams\n",
    "NUM_CLASSES = 4\n",
    "MAX_EPOCHS = 500\n",
    "\n",
    "# Big model takes lots of space in memory -> small batch size fits in\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_VAL = 8\n",
    "BATCH_SIZE_TEST  = 8\n",
    "\n",
    "NUM_WORKERS = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ACDCDataModule(\"database\", BATCH_SIZE_TRAIN,BATCH_SIZE_VAL,BATCH_SIZE_TEST,(256,256,1), convert_to_single=False,num_workers=NUM_WORKERS)\n",
    "datamodule.setup(\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "\n",
    "\n",
    "wandb_logger = pl.loggers.WandbLogger(project=\"Medical Image Segmentation\")\n",
    "\n",
    "model = smp.Unet('resnet34',classes=NUM_CLASSES, in_channels=1)\n",
    "\n",
    "# model = fcn_resnet50()\n",
    "# model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# model.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "# model = UNet(n_channels=1, n_classes=4)\n",
    "\n",
    "# model = SimpleSegmentationModel(1,4)\n",
    "\n",
    "wandb_logger.watch(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = smp.losses.DiceLoss(mode=\"multiclass\", ignore_index=0)\n",
    "# loss = ResnetLoss(criterion)\n",
    "loss = criterion\n",
    "# loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to add new preprocessing arg, to include pretrained model preprocessing\n",
    "# preprocess_input = smp.encoders.get_preprocessing_fn('resnet18', pretrained='imagenet')\n",
    "\n",
    "\n",
    "\n",
    "segmenter = SemanticSegmanter(model = model, learning_rate=1e-4 ,criterion=loss)\n",
    "\n",
    "# tsmp.metrics.functional.IoU or torch metric?\n",
    "# do we need this?\n",
    "# metric = smp.metrics.functional.IoU(threshold=0.5)\n",
    "\n",
    "\n",
    "# Configure callbacks and logger\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  patience=5 ,mode=\"min\", verbose=True)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=500,  logger=wandb_logger,callbacks = [RichProgressBar(), early_stopping])\n",
    "trainer.fit(segmenter, datamodule=datamodule)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
